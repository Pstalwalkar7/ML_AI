{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwGWNHs2xIsx"
   },
   "source": [
    "# Logistic Regression Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcaBeePgu_Tu"
   },
   "source": [
    "## Multi-class classification of MNIST using Logistic Regression\n",
    "\n",
    "The multi-class scenario for logistic regression is quite similar to the binary case, except that the label $y$ is now an integer in {1, ...., K} where $K$ is the number of classes. In this excercise you will be provided with handwritten digit images. Write the code and compute the test accuracy by training a logistic regression based classifier in (i) one-vs-one, and (ii) one-vs-all setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running importer\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        #print('searching: %s'%nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        #print('searching: %s' % nb_path)\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        #print('Found %d cells'%len(nb.cells))\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "\n",
    "#  register the NotebookFinder with sys.meta_path\n",
    "print('running importer')\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9944,
     "status": "ok",
     "timestamp": 1596983406360,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "ManRVu7IsIjp",
    "outputId": "b48dd937-f2d5-4762-af1a-44fa03c44d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "from utils import plot_decision_boundary, get_accuracy, get_prediction\n",
    "from utils import plot_2D_input_datapoints, generate_gifs, sigmoid, normalize\n",
    "import math\n",
    "import gif\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9918,
     "status": "ok",
     "timestamp": 1596983406361,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "xbV2U06Cs45b"
   },
   "outputs": [],
   "source": [
    "# Let's initialize our weights using uniform distribution\n",
    "def weight_init_uniform_dist(X, y):\n",
    "  \n",
    "    np.random.seed(312)\n",
    "    n_samples, n_features = np.shape(X)\n",
    "    _, n_outputs = np.shape(y)\n",
    "\n",
    "    limit = 1 / math.sqrt(n_features)\n",
    "    weights = np.random.uniform(-limit, limit, (n_features, n_outputs))\n",
    "    weights[-1] = 0\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36195,
     "status": "ok",
     "timestamp": 1596983432936,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "SAAbK03fLCR1"
   },
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "\n",
    "# One hot encoding of our output label vector y\n",
    "def one_hot(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "# Loading dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Absorbing weight b of the hyperplane\n",
    "X = digits.data\n",
    "b_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, b_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36177,
     "status": "ok",
     "timestamp": 1596983432939,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "yzdjTbEYLvPK",
    "outputId": "76ed5c87-3298-433d-cf76-d68026c46342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig()\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36148,
     "status": "ok",
     "timestamp": 1596983432942,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "3CIYTv4x65As",
    "outputId": "d9f59ee0-8392-4ba9-8cb8-11afc1669fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1308, 65)\n",
      "Validation dataset:  (188, 65)\n",
      "Test dataset:  (301, 65)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train, val, and test set.\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.167)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36132,
     "status": "ok",
     "timestamp": 1596983432945,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "d3NzkO4s68RX"
   },
   "outputs": [],
   "source": [
    "# Normalizing X_train and absorbing weight b of the hyperplane\n",
    "X_normalized_train = normalize(X_train[:, :64])\n",
    "\n",
    "b_ones = np.ones((len(X_normalized_train), 1))\n",
    "X_normalized_train = np.hstack((X_normalized_train, b_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36096,
     "status": "ok",
     "timestamp": 1596983432947,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "pYrK4fK3iyyk",
    "outputId": "a73d5605-db30-4099-f72e-9cca8e2fe3cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing One vs. One Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    return 2*(x>=0)-1\n",
    "\n",
    "set_lim = 1000\n",
    "set_tries = 50\n",
    "\n",
    "def one_vs_one_classifer(X, Y, lr=(1.0/10), n_epochs=set_lim, debug=False):\n",
    "    z = X.shape\n",
    "    n = z[0]\n",
    "    d = z[1]\n",
    "    sz = (d,1)\n",
    "    W = np.random.uniform(0,1,size=sz)\n",
    "    acc = -1\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = sign(np.matmul(X,W))\n",
    "        incorrect = y_pred!=Y\n",
    "        sm = incorrect.sum()\n",
    "        acc = sm/n\n",
    "        incorrect = incorrect * Y\n",
    "        W = W + lr * np.matmul(np.transpose(X),incorrect)\n",
    "        pr_ep = (n_epochs//5)\n",
    "        if  debug and epoch%pr_ep == 0:\n",
    "            pr_ac = round(100*acc,2)\n",
    "            print(\"Epoch : \", epoch, \"The Incorrect Percentage : \", pr_ac)\n",
    "    return W, acc\n",
    "\n",
    "def all_1v1_classifiers(X, Y, lr=1/10.0, n_epochs=set_lim):\n",
    "    z = X.shape\n",
    "    n = z[0]\n",
    "    d = z[1]\n",
    "    k = Y.shape[-1]\n",
    "    dim = (k, k, d, 1)\n",
    "    Ws = np.zeros(dim)\n",
    "    ACCs = np.ones((k, k))\n",
    "    ACCs *= -1\n",
    "    for i in range(k):\n",
    "        j = i+1\n",
    "        while j<k:\n",
    "            Z = Y[:,i]\n",
    "            ci = (Z==1)\n",
    "            ZZ = Y[:,j]\n",
    "            cj = (ZZ==1)\n",
    "            ex = [X[ci], X[cj]]\n",
    "            ex = np.vstack(ex)\n",
    "            ex = np.vstack([X[ci], X[cj]])\n",
    "            precalc_i = np.ones((ci.sum(),1))\n",
    "            precalc_j = np.ones((cj.sum(),1))\n",
    "            ey = [-1*precalc_i, precalc_j]\n",
    "            ey = np.vstack(ey)\n",
    "            ANS = one_vs_one_classifer(ex, ey, lr, n_epochs)\n",
    "            Ws[i,j] = ANS[0]\n",
    "            ACCs[i,j] = ANS[1]\n",
    "            j+=1\n",
    "    return Ws, ACCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1v1_tree(tree, label):\n",
    "    sm = sum(label)\n",
    "    if sm==1:\n",
    "        return [None,label]\n",
    "    i = tree[0][0]\n",
    "    j = tree[0][1]\n",
    "    treei = []\n",
    "    treej = []\n",
    "    for node in tree:\n",
    "        if j not in node:\n",
    "            treei.append(node)\n",
    "        if i not in node:\n",
    "            treej.append(node)\n",
    "    \n",
    "    labeli = label.copy()\n",
    "    labelj = label.copy()\n",
    "    labeli[j] = 0\n",
    "    labelj[i] = 0\n",
    "    p1 = get_1v1_tree(treei, labeli)\n",
    "    p2 = get_1v1_tree(treej, labelj)\n",
    "    return [ [i,j], [p1, p2] ]\n",
    "\n",
    "def classify_1v1_single(x, Ws, tree):\n",
    "    node = tree[0]\n",
    "    label = tree[1]\n",
    "    if node != None:\n",
    "        i = node[0]\n",
    "        j = node[1]\n",
    "        calc = x@Ws[i,j][:,0]\n",
    "        res = (sign(calc) + 1)//2\n",
    "        return classify_1v1_single(x, Ws, label[res])\n",
    "    return label\n",
    "\n",
    "def classify_1v1(X, Ws, tree):\n",
    "    n = X.shape[0]\n",
    "    k = 10\n",
    "    dim = (n,k)\n",
    "    y_preds = np.zeros(dim)\n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        y_preds[i] = classify_1v1_single(x, Ws, tree)\n",
    "    return y_preds\n",
    "\n",
    "def get_acc(y_pred, y):\n",
    "    p1 = np.argmax(y_pred, axis=1)\n",
    "    p2 = np.argmax(y, axis=1)\n",
    "    P = np.count_nonzero(p1 == p2)\n",
    "    return  P/y.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = all_1v1_classifiers(X_train, Y_train)\n",
    "Ws = store[0]\n",
    "k = Y_train.shape[1]\n",
    "ACCs = store[1]\n",
    "temp = np.unravel_index(np.argsort(ACCs, axis=None), ACCs.shape)\n",
    "temp = np.transpose(temp)\n",
    "cnt = (k*(k-1))//2\n",
    "tree_order_desc = np.vstack(temp[::-1][:cnt])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Classification Tree using Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_acc: 96.277\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "np.random.seed(1)\n",
    "tries = set_tries\n",
    "O = np.ones((k))\n",
    "best_tree = None\n",
    "max_val_acc = -10\n",
    "for _ in range(tries):\n",
    "    tree_order = tree_order_desc.copy()\n",
    "    np.random.shuffle(tree_order)\n",
    "    tree = get_1v1_tree(tree_order, O)\n",
    "    val_acc = classify_1v1(X_val, Ws, tree)\n",
    "    val_acc = get_acc(val_acc, Y_val)\n",
    "    if val_acc <= max_val_acc:\n",
    "        pass\n",
    "    else:\n",
    "        max_val_acc = val_acc\n",
    "        best_tree = deepcopy(tree)\n",
    "\n",
    "tree = deepcopy(best_tree)\n",
    "val = 100*max_val_acc\n",
    "print(\"Best val_acc:\", round(val, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs. One Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs. One classification:\n",
      "Training accuracy: 100.000 percent\n",
      "Validation accuracy: 96.277 percent\n",
      "Testing accuracy: 95.017 percent\n"
     ]
    }
   ],
   "source": [
    "train_acc_1v1 = classify_1v1(X_train, Ws, tree)\n",
    "train_acc_1v1 = get_acc(train_acc_1v1, Y_train)\n",
    "\n",
    "val_acc_1v1 = classify_1v1(X_val, Ws, tree)\n",
    "val_acc_1v1 = get_acc(val_acc_1v1, Y_val)\n",
    "\n",
    "test_acc_1v1 = classify_1v1(X_test, Ws, tree)\n",
    "test_acc_1v1 = get_acc(test_acc_1v1, Y_test)\n",
    "\n",
    "print(\"One vs. One classification:\")\n",
    "val = 100*train_acc_1v1\n",
    "print(\"Training accuracy:\", \"%.3f percent\" % (val))\n",
    "val = 100*val_acc_1v1\n",
    "print(\"Validation accuracy:\", \"%.3f percent\" % (val))\n",
    "val = 100*test_acc_1v1\n",
    "print(\"Testing accuracy:\", \"%.3f percent\" % (val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing One vs. All Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all_classifier(x,y,lr=1/10.0,max_iters=set_lim,debug=False):\n",
    "    sh = x.shape\n",
    "    n = sh[0]\n",
    "    d = sh[1]\n",
    "    c = y.shape[1]\n",
    "    dim = (c,d)\n",
    "    W = np.random.uniform(-1,1,dim)\n",
    "    for i in range(max_iters):\n",
    "        sign_compute = sign(x@W.T)\n",
    "        incorrect_preds = (sign_compute != y)\n",
    "        W += lr*np.transpose(np.matmul(np.transpose(x),y*incorrect_preds))\n",
    "        sm = incorrect_preds.sum()\n",
    "        if sm != 0:\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "        predef = (max_iters//5)\n",
    "        if debug and i%predef == 0:\n",
    "            val = 100*incorrect_preds.sum()/incorrect_preds.size\n",
    "            print(\"Epoch:\", i+1, \"\\tIncorrect Predictions:\", \"%.3f percent\" % (val))\n",
    "    return W\n",
    "\n",
    "def classify_1v_all(x, w):\n",
    "    ANS = x@w.T\n",
    "    return one_hot(np.argmax(ANS, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "Y_train_modified = Y_train.copy()\n",
    "pre = -1\n",
    "Y_train_modified[Y_train==0] = pre\n",
    "set_lim = 1000\n",
    "W = one_vs_all_classifier(X_train, Y_train_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs. All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs. One classification:\n",
      "Training accuracy: 97.630 percent\n",
      "Validation accuracy: 95.745 percent\n",
      "Testing accuracy: 94.352 percent\n"
     ]
    }
   ],
   "source": [
    "train_acc_1v_all = classify_1v_all(X_train, W)\n",
    "train_acc_1v_all = get_acc(train_acc_1v_all, Y_train)\n",
    "\n",
    "val_acc_1v_all = classify_1v_all(X_val, W)\n",
    "val_acc_1v_all = get_acc(val_acc_1v_all, Y_val)\n",
    "\n",
    "test_acc_1v_all = classify_1v_all(X_test, W)\n",
    "test_acc_1v_all = get_acc(test_acc_1v_all, Y_test)\n",
    "\n",
    "print(\"One vs. One classification:\")\n",
    "val = 100*train_acc_1v_all\n",
    "print(\"Training accuracy:\", \"%.3f percent\" % (val))\n",
    "val = 100*val_acc_1v_all\n",
    "print(\"Validation accuracy:\", \"%.3f percent\" % (val))\n",
    "val = 100*test_acc_1v_all\n",
    "print(\"Testing accuracy:\", \"%.3f percent\" % (val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegression_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
