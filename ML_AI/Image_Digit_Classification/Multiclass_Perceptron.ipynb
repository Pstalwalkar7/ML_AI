{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223975,
     "status": "ok",
     "timestamp": 1596984132348,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "  b = -1 * np.ones((a.size, a.max()+1))\n",
    "  b[np.arange(a.size), a] = 1\n",
    "  return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223957,
     "status": "ok",
     "timestamp": 1596984132353,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "233f09b1-7641-4c60-c21d-74a2264f8bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223939,
     "status": "ok",
     "timestamp": 1596984132358,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "66a50417-5c21-4158-f029-20ef755e50f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL0UlEQVR4nO3d34tc9RnH8c/HNcEfSVyIVtSIqVACInQTJFQC0iYqsUr0ohcJVIi0pBetGBoQ7U2Tf0DSiyKEqAkYIxoNFGmtAV1EaLVJXGt0YzEh4jbq+oOwiYUGzdOLOSlpuu2eXc/3zOw87xcMmdmdOc+zu/nMOWfmzHkcEQLQ3y7odgMAyiPoQAIEHUiAoAMJEHQgAYIOJNATQbe92vZ7tt+3/VDhWo/bHrd9qGSdc+pda/sV26O237H9QOF6F9l+w/ZbVb0tJetVNQdsv2n7hdK1qnrHbL9te8T2/sK1Bm3vsX24+hveXLDWkupnOnuZsL2xkYVHRFcvkgYkHZF0vaS5kt6SdEPBerdIWibpUEs/31WSllXX50v6W+Gfz5LmVdfnSHpd0vcK/4y/lPSUpBda+p0ek3R5S7V2SvppdX2upMGW6g5I+ljSdU0srxfW6MslvR8RRyPitKSnJd1dqlhEvCrpi1LLn6TeRxFxsLp+UtKopGsK1ouIOFXdnFNdih0VZXuRpDslbS9Vo1tsL1BnxfCYJEXE6Yg40VL5VZKORMQHTSysF4J+jaQPz7k9poJB6CbbiyUtVWctW7LOgO0RSeOS9kVEyXpbJT0o6UzBGucLSS/ZPmB7Q8E610v6VNIT1a7JdtuXFqx3rrWSdje1sF4Iuif5Wt8dl2t7nqTnJG2MiImStSLi64gYkrRI0nLbN5aoY/suSeMRcaDE8v+PFRGxTNIdkn5u+5ZCdS5UZzfv0YhYKulLSUVfQ5Ik23MlrZH0bFPL7IWgj0m69pzbiyQd71IvRdieo07Id0XE823VrTYzhyWtLlRihaQ1to+ps8u10vaThWr9W0Qcr/4dl7RXnd2/EsYkjZ2zRbRHneCXdoekgxHxSVML7IWg/0XSd2x/u3omWyvpd13uqTG2rc4+3mhEPNJCvStsD1bXL5Z0q6TDJWpFxMMRsSgiFqvzd3s5In5cotZZti+1Pf/sdUm3SyryDkpEfCzpQ9tLqi+tkvRuiVrnWacGN9ulzqZJV0XEV7Z/IemP6rzS+HhEvFOqnu3dkr4v6XLbY5J+HRGPlaqnzlrvXklvV/vNkvSriPh9oXpXSdppe0CdJ/JnIqKVt71acqWkvZ3nT10o6amIeLFgvfsl7apWQkcl3VewlmxfIuk2ST9rdLnVS/kA+lgvbLoDKIygAwkQdCABgg4kQNCBBHoq6IUPZ+xaLepRr9v1eiroktr8Zbb6h6Me9bpZr9eCDqCAIgfM2O7ro3AGBgam/ZgzZ87oggtm9rx69dVXT/sxp06d0rx582ZUb+HChdN+zOeffz6jx0nSyZMnp/2YiYkJLViwYEb1jhw5MqPHzRYR8V8fFOv6IbCz0fz581utt2nTplbrrV+/vtV6w8PDrda75557Wq3XC9h0BxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQQK2gtzkyCUDzpgx6dZLB36pzCtobJK2zfUPpxgA0p84avdWRSQCaVyfoaUYmAf2qzodaao1Mqj4o3/ZndgHUUCfotUYmRcQ2Sduk/v+YKjDb1Nl07+uRSUAGU67R2x6ZBKB5tU48Uc0JKzUrDEBhHBkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABJrXMwI4dO1qtd/fd7X4qeMuWLa3Wa3syTNv12v7/MhnW6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigzkimx22P2z7URkMAmldnjb5D0urCfQAoaMqgR8Srkr5ooRcAhbCPDiTQ2MdUmb0G9K7Ggs7sNaB3sekOJFDn7bXdkv4kaYntMds/Kd8WgCbVGbK4ro1GAJTDpjuQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQT6Yvba4sWLW63X9iy0nTt3tlpv8+bNrdYbHBxstd7Q0FCr9XoBa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kUOfkkNfafsX2qO13bD/QRmMAmlPnWPevJG2KiIO250s6YHtfRLxbuDcADakze+2jiDhYXT8paVTSNaUbA9Ccae2j214saamk10s0A6CM2h9TtT1P0nOSNkbExCTfZ/Ya0KNqBd32HHVCvisinp/sPsxeA3pXnVfdLekxSaMR8Uj5lgA0rc4++gpJ90paaXukuvywcF8AGlRn9tprktxCLwAK4cg4IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ9MXstRMnTnS7haJ27NjR7RaK6ve/Xy9gjQ4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEE6pwF9iLbb9h+q5q9tqWNxgA0p86x7v+UtDIiTlXnd3/N9h8i4s+FewPQkDpngQ1Jp6qbc6oLAxqAWaTWPrrtAdsjksYl7YsIZq8Bs0itoEfE1xExJGmRpOW2bzz/PrY32N5ve3/TTQL4Zqb1qntEnJA0LGn1JN/bFhE3RcRNDfUGoCF1XnW/wvZgdf1iSbdKOly6MQDNqfOq+1WSdtoeUOeJ4ZmIeKFsWwCaVOdV979KWtpCLwAK4cg4IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ9MXstaGhoW63APQ01uhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IoHbQqyEOb9rmxJDALDOdNfoDkkZLNQKgnLojmRZJulPS9rLtACih7hp9q6QHJZ0p2AuAQupMarlL0nhEHJjifsxeA3pUnTX6CklrbB+T9LSklbafPP9OzF4DeteUQY+IhyNiUUQslrRW0ssR8ePinQFoDO+jAwlM61RSETGszthkALMIa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwn0xey1kZGRbrdQ1GWXXdZqvcHBwVbrtT07b/Pmza3W6wWs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBArUNgq1M9n5T0taSvOKUzMLtM51j3H0TEZ8U6AVAMm+5AAnWDHpJesn3A9oaSDQFoXt1N9xURcdz2tyTts304Il499w7VEwBPAkAPqrVGj4jj1b/jkvZKWj7JfZi9BvSoOtNUL7U9/+x1SbdLOlS6MQDNqbPpfqWkvbbP3v+piHixaFcAGjVl0CPiqKTvttALgEJ4ew1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAKOiOYXaje/0B4yPDzc7RaKOnbsWLdbKGr9+vXdbqGoiPD5X2ONDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRqBd32oO09tg/bHrV9c+nGADSn7gCH30h6MSJ+ZHuupEsK9gSgYVMG3fYCSbdIWi9JEXFa0umybQFoUp1N9+slfSrpCdtv2t5eDXL4D7Y32N5ve3/jXQL4RuoE/UJJyyQ9GhFLJX0p6aHz78RIJqB31Qn6mKSxiHi9ur1HneADmCWmDHpEfCzpQ9tLqi+tkvRu0a4ANKruq+73S9pVveJ+VNJ95VoC0LRaQY+IEUnsewOzFEfGAQkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgNlrMzA4ONhqva1bt7Zab2hoqNV6bc9CGxkZabVe25i9BiRF0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJDBl0G0vsT1yzmXC9sY2mgPQjCnPGRcR70kakiTbA5L+Lmlv4b4ANGi6m+6rJB2JiA9KNAOgjOkGfa2k3SUaAVBO7aBX53RfI+nZ//F9Zq8BParuAAdJukPSwYj4ZLJvRsQ2Sduk/v+YKjDbTGfTfZ3YbAdmpVpBt32JpNskPV+2HQAl1B3J9A9JCwv3AqAQjowDEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSKDV77VNJM/nM+uWSPmu4nV6oRT3qtVXvuoi44vwvFgn6TNneHxE39Vst6lGv2/XYdAcSIOhAAr0W9G19Wot61OtqvZ7aRwdQRq+t0QEUQNCBBAg6kABBBxIg6EAC/wKMjH+/mXElygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "#### Write your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signum(x):\n",
    "    return 1 if x>=0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(X_train,Y_train,epochs):\n",
    "    sh = X_train.shape\n",
    "    dim = (sh[1],1)\n",
    "    w = np.zeros(dim)\n",
    "    m = 1\n",
    "    len_X = len(X_train)\n",
    "    while(epochs>0 and m>0):\n",
    "        m = 0\n",
    "        for i in range(len_X):\n",
    "            xi = X_train[i]\n",
    "            yi = Y_train[i]\n",
    "            d_p = np.dot(np.transpose(w),xi)\n",
    "            y_hat = signum(d_p[0])\n",
    "            val = yi * y_hat\n",
    "            if val >= 0:\n",
    "                pass\n",
    "            else:\n",
    "                m+=1\n",
    "                w = np.transpose(w) + xi*yi\n",
    "                w = np.transpose(w)\n",
    "        epochs -= 1\n",
    "    return w,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictclass(X_fit, Y_fit, weights):\n",
    "    x_sh = X_fit.shape\n",
    "    y_sh = Y_fit.shape\n",
    "    predictedclass = np.zeros(x_sh[0])\n",
    "    for i in range(x_sh[0]):\n",
    "        for j in range(y_sh[1]):\n",
    "            W = weights[:,j]\n",
    "            X = X_fit[i,:]\n",
    "            if np.dot(W,X) > 0:\n",
    "                predictedclass[i] = j\n",
    "                break\n",
    "    return predictedclass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_val,predictedclass):\n",
    "    sh = Y_val.shape\n",
    "    error = 0\n",
    "    req = 1.0\n",
    "    numsamples = sh[0]\n",
    "    for i in range(numsamples):\n",
    "        Actualclass = Y_val[i,:]\n",
    "        ind = int(predictedclass[i])\n",
    "        val = Actualclass[ind]\n",
    "        if val != req:\n",
    "            error = error + 1\n",
    "    ret = error/numsamples\n",
    "    ret = 1-ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for validation set : 91.11111111111111%\n",
      "Accuracy for testing set : 89.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "x_sh = X_train.shape\n",
    "y_sh = Y_train.shape\n",
    "weights = np.zeros((x_sh[1],y_sh[1]))\n",
    "for i in range(y_sh[1]):\n",
    "    temp = Y_train[:,i]\n",
    "    T = Perceptron(X_train, temp, 99)\n",
    "    w = T[0]\n",
    "    err = T[1]\n",
    "    temp = w[:,0]\n",
    "    weights[:,i] = temp\n",
    "\n",
    "predictedclass = predictclass(X_val,Y_val,weights)\n",
    "acc = accuracy(Y_val,predictedclass)\n",
    "print(\"Accuracy for validation set : \"+str(acc*100)+\"%\")\n",
    "\n",
    "predictedclass = predictclass(X_test,Y_test,weights)\n",
    "acc = accuracy(Y_test,predictedclass)\n",
    "print(\"Accuracy for testing set : \"+str(acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
